import os
import numpy as np
import random


def video_generator(data, batch_size, seq_len, input_shape, num_classes):
    '''
    :param data: The data generated by get data_list
    :param batch_size:
    :param seq_len:
    :param input_shape: tuple: the shape of image, e.g. (216, 216, 3)
                        or int: the length of 1-D vector generated by CNN model
    :param num_classes:
    :return:
    '''
    if isinstance(input_shape, tuple):
        x_shape = (batch_size, seq_len, input_shape[0], input_shape[1], input_shape[2])
    elif isinstance(input_shape, int):
        x_shape = (batch_size, seq_len, input_shape)
    else:
        raise ValueError('Input shape is neither 1D or 3D')
    y_shape = (batch_size, num_classes)
    index = 0
    while True:
        batch_x = np.ndarray(x_shape)
        batch_y = np.zeros(y_shape)
        for i in range(batch_size):
            step = random.randint(1, len(data) - 1)  # approach a random-size step to get the next video sample
            index = (index + step) % len(data)
            clip_dir, clip_class = data[index]
            batch_y[i, clip_class - 1] = 1
            clip_dir = os.path.splitext(clip_dir)[0] + '.npy'
            while not os.path.exists(clip_dir):
                index = (index + 1) % len(data)
                clip_dir, class_idx = data[index]
            clip_data = np.load(clip_dir)
            if clip_data.shape != batch_x.shape[1:]:
                raise ValueError('The number of time sequence is inconsistent with '
                                 'the video data')
            batch_x[i] = clip_data
        yield batch_x, batch_y


def video_image_generator(data_list, batch_size, seq_len, img_size, num_classes):
    '''
        generate images extracted from videos
    '''
    batch_image_shape = (batch_size, img_size[0], img_size[1], 3)
    batch_image = np.ndarray(batch_image_shape)

    video_gen = video_generator(data_list, batch_size, seq_len, img_size, num_classes)

    while True:
        batch_video, batch_label = next(video_gen)
        for idx, video in enumerate(batch_video):
            sample_frame_idx = random.randint(0, seq_len - 1)
            sample_frame = video[sample_frame_idx]
            batch_image[idx] = sample_frame

        yield batch_image, batch_label


def get_data_list(list_dir, video_dir):
    '''
    Input parameters:
    list_dir: 'root_dir/data/ucfTrainTestlist'
    video_dir: directory that stores source train and test data

    Return value:
    test_data/train_data: list of tuples (clip_dir, class index)
    class_index: dictionary of mapping (class_name->class_index)
    '''
    train_dir = os.path.join(video_dir, 'train')
    test_dir = os.path.join(video_dir, 'test')
    testlisttxt = 'testlist01.txt'
    trainlisttxt = 'trainlist01.txt'

    testlist = []
    txt_path = os.path.join(list_dir, testlisttxt)
    with open(txt_path) as fo:
        for line in fo:
            testlist.append(line.rstrip())

    trainlist = []
    txt_path = os.path.join(list_dir, trainlisttxt)
    with open(txt_path) as fo:
        for line in fo:
            trainlist.append(line[:line.rfind(' ')])

    class_index = dict()
    class_dir = os.path.join(list_dir, 'classInd.txt')
    with open(class_dir) as fo:
        for line in fo:
            class_number, class_name = line.split()
            class_number = int(class_number)
            class_index[class_name] = class_number

    train_data = []
    for i, clip in enumerate(trainlist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(train_dir, clip)
        train_data.append((dst_dir, class_index[clip_class]))

    test_data = []
    for i, clip in enumerate(testlist):
        clip_class = os.path.dirname(clip)
        dst_dir = os.path.join(test_dir, clip)
        test_data.append((dst_dir, class_index[clip_class]))

    return train_data, test_data, class_index
